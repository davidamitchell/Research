---
title: "AI for Control Testing, Gap Identification, and Policies/Standards Reviews"
added: 2026-02-28
status: backlog
priority: high
tags: [ai-strategy, grc, control-testing, compliance-automation, internal-audit, risk-management, financial-services]
started: ~
completed: ~
output: [knowledge]
---

# AI for Control Testing, Gap Identification, and Policies/Standards Reviews

## Research Question

Which organisations are using AI to automate control testing, identify control gaps, or conduct policies and standards reviews — and what does the current vendor, practitioner, and regulatory landscape look like for AI-assisted assurance in financial services?

## Scope

**In scope:**
- Automated control testing: AI systems that sample, execute, or evaluate control performance continuously or periodically
- Control gap identification: AI analysis of control frameworks against current practice to surface deficiencies
- Policies and standards reviews: AI tools that parse internal policies, regulatory standards, and frameworks to identify gaps, conflicts, or outdated provisions
- Vendor landscape: who is building and selling these tools (e.g. AuditBoard, Galvanize/Diligent, ServiceNow GRC, KPMG Clara, Deloitte OmniAI, PwC Halo, EY Helix)
- Practitioner case studies: how internal audit, compliance, and operational risk functions are deploying these tools
- NZ financial services context: RBNZ-supervised entities, Big-4 audit firms operating in NZ

**Out of scope:**
- AI as a risk management tool in the credit/fraud/AML sense — covered by `ai-strategy-risk-reduction-focus.md`
- AI security applications — covered by `ai-strategy-security-focus.md`
- General GRC platform capabilities not involving AI

**Constraints:** Focus on production deployments or credible pilots, not vendor marketing claims. Prefer disclosed outcomes and governance models over white-paper descriptions.

## Context

The AI strategy research item (completed 2026-02-28) identified a four-type use-case typology. Control testing automation sits primarily in Type 2 (agentic builders that generate artefacts) and Type 3 (delegated authority agents — AI making a determination such as "this control is operating effectively"). The governance architecture for Type 3 control testing agents is an open question: who reviews AI-generated assurance conclusions, and what is the regulatory acceptability of AI-assisted audit evidence?

This is a high-priority area because: (a) it is commercially active now, not aspirational; (b) it affects the external audit and internal assurance functions of regulated entities; (c) it directly intersects with RBNZ BS11 (outsourcing), RBNZ BS2A (internal capital adequacy), and DORA (ICT risk controls testing) obligations.

## Approach

1. **Vendor landscape scan** — identify the 8–10 major platforms and what specific AI-assisted assurance capabilities they claim (continuous control monitoring, policy-to-standard gap analysis, automated testing workpaper generation).
2. **Practitioner evidence** — find disclosed case studies from internal audit, compliance, or risk functions describing actual deployments: what was automated, what outcomes were achieved, what governance was in place.
3. **Regulatory acceptability** — review guidance from audit standard-setters (IAASB, PCAOB, AUASB) and prudential regulators on AI-generated assurance evidence. Is AI-assisted control testing evidence acceptable? What oversight is required?
4. **Gap identification tooling** — specifically focus on AI tools that ingest regulatory standards (e.g. DORA, PCI-DSS, NIST CSF) and compare against internal policy/control inventories to surface gaps.
5. **NZ applicability** — which vendors, frameworks, and governance models are directly relevant to NZ-supervised institutions?

## Sources

- [ ] IAASB: Technology position papers and ISA revisions for AI use in audit (2023–2025)
- [ ] PCAOB: Inspection findings on automated audit tools
- [ ] ISACA: COBIT and audit automation guidance
- [ ] IIA (Institute of Internal Auditors): AI in internal audit position papers (2024–2025)
- [ ] AuditBoard, Diligent (Galvanize), LogicGate, ServiceNow GRC product documentation
- [ ] Big-4 audit firm publications: KPMG Clara Audit, EY Helix, PwC Halo, Deloitte OmniAI
- [ ] DORA Article 24–27: ICT operational resilience testing — AI-assisted testing implications
- [ ] RBNZ: Any supervisory expectations on automated assurance or model-generated evidence
- [ ] Gartner / Forrester: GRC platform market reports 2024–2025

---

## Findings

*(Fill in when completing.)*

### Executive Summary

### Key Findings

1.
2.

### Evidence Map

| Claim | Source | Confidence | Notes |
|---|---|---|---|
| | | high / medium / low | |

### Assumptions

- **Assumption:** ... **Justification:** ...

### Analysis

### Risks, Gaps, and Uncertainties

-

### Open Questions

-

---

## Output

- Type: knowledge
- Description:
- Links:
